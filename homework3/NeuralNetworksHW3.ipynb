{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "95.71\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(z):  # 1/1+e^-z\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def softmax(z):  # e^z/ suma de e^z\n",
    "    e_z = np.exp(z)\n",
    "    return e_z / np.sum(e_z)\n",
    "\n",
    "\n",
    "def init_weights(layers_sizes):\n",
    "    weights = []\n",
    "    #normal -> Draw random samples from a normal (Gaussian) distribution.\n",
    "    # weight initialization to avoid saturation of the neurons  \n",
    "    # random values from a normal distribution with mean  0 and standard deviation\n",
    "    # standard deviation -> 1/sqrt(total number of connection that go into that neuron -> 784)\n",
    "    weights = [np.random.normal(0, np.power(np.sqrt(layers_sizes[i - 1]), (-1)), (layers_sizes[i], layers_sizes[i - 1]))\n",
    "               for i in range(1, len(layers_sizes))]\n",
    "    return weights\n",
    "\n",
    "\n",
    "def init_biases(layers_sizes):\n",
    "    biases = []\n",
    "    biases = [np.random.standard_normal( layers_sizes[i]) for i in range(1, len(layers_sizes))]\n",
    "    return biases\n",
    "\n",
    "\n",
    "def update_weights(error, previous, learning_rate):\n",
    "    gradient = error * previous\n",
    "    return learning_rate * gradient\n",
    "\n",
    "\n",
    "def update_biases(error, learning_rate):\n",
    "    copyError = np.ravel(error)  # A 1-D array, containing the elements of the input, is returned\n",
    "    return learning_rate * copyError\n",
    "\n",
    "\n",
    "def train(train_set):\n",
    "    images = train_set[0]\n",
    "    labels = train_set[1]\n",
    "    layers_sizes = [784, 100, 10]\n",
    "\n",
    "    weights = init_weights(layers_sizes)\n",
    "\n",
    "    biases = init_biases(layers_sizes)\n",
    "\n",
    "    nrIterations = 1\n",
    "\n",
    "    while nrIterations > 0:\n",
    "        # pentru fiecare imagine din train set\n",
    "        for i in range(0, len(images)):\n",
    "            # calculam z pentru imaginea de pe poz i din dataset trecut prin toti neuronii de la l1 catre l2\n",
    "            # si ii aplicam functia de activare sigmoid\n",
    "            Z1 = np.add(np.dot(weights[0], images[i]), biases[0])\n",
    "            Z1sigmoid = sigmoid(Z1)  # (1,100)\n",
    "            # calculam z pentru ce am obtinut la pasul anterior l2->l3 si il trecem prin functia de activare softmax      \n",
    "            Z2 = np.add(np.dot(weights[1], Z1sigmoid), biases[1])\n",
    "            Z2softmax = softmax(Z2)  # (1,10)\n",
    "\n",
    "# vector care reprez targetul imaginii: initial este un vector cu 0 unde punem 1 pe pozitia poz unde poz este labelu img curente\n",
    "            target = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            poz = labels[i]\n",
    "            target[poz] = 1\n",
    "\n",
    "# calculam eroarea prin scaderea targetului din z pentru ultimul layer trecut prin softmax -> cross entropy slide 15/4\n",
    "            error2 = Z2softmax - target\n",
    "\n",
    "            # ii facem transpusa (valorile sa fie cate una pe linie) pentru a putea inmulti cu weights care are (10,100)\n",
    "            error2 = error2.reshape((10, 1))\n",
    "\n",
    "            # pentru a calcula eroarea de la layer precedent - prima eroare folosim formula curs3/slide 34\n",
    "            # outputul * (1- output) *  suma (weights* eroarea lu final layer)\n",
    "            # o sa se adune de la neuronul 1 din l2 l3n1+l3n2+..l3n10\n",
    "# se aduna matricea produsul rezultat pe coloane a.i. vom avea suma fiecarui neuron din l2 pentru toti neuronii din l3\n",
    "            error1 = (Z1sigmoid * (1 - Z1sigmoid)) * np.sum(weights[1] * error2, axis=0)\n",
    "\n",
    "            learningRate = 0.08\n",
    "\n",
    "# facem transpusa -> reshape la 100,1 pentru a putea inm cu matricea de imagine (o linie cu 784 elem) -> sa fie o singura coloana\n",
    "            error1 = error1.reshape((100, 1))\n",
    "\n",
    "            # https://hmkcode.com/ai/backpropagation-step-by-step/\n",
    "\n",
    "            # updatam weights si biases -> scadem din weights actual learning rateul imn cu gradientul\n",
    "            # gradientul este eroarea * ce am obtinut de la hidden layer (outputul) sau pt weights[0] inputul\n",
    "            # pt bias gradientul este eroarea\n",
    "            weights[1] = weights[1] - update_weights(error2, Z1sigmoid, learningRate)\n",
    "            weights[0] = weights[0] - update_weights(error1, images[i], learningRate)\n",
    "\n",
    "            biases[1] = biases[1] - update_biases(error2, learningRate)\n",
    "            biases[0] = biases[0] - update_biases(error1, learningRate)\n",
    "\n",
    "        nrIterations = nrIterations - 1\n",
    "\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "def acuratete(weights, biases, test_set):\n",
    "    corecte = 0\n",
    "\n",
    "    images = test_set[0]\n",
    "    labels = test_set[1]\n",
    "    for i in range(0, len(images)):\n",
    "        Z1sigmoid = sigmoid(np.add(np.dot(weights[0], images[i]), biases[0]))\n",
    "        Z2softmax = softmax(np.add(np.dot(weights[1], Z1sigmoid), biases[1]))\n",
    "        if np.argmax(Z2softmax) == labels[i]:\n",
    "            corecte = corecte + 1\n",
    "    print(\"Accuracy:\")\n",
    "    print(corecte / len(images) * 100)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load dataset\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as fin:\n",
    "        train_set, valid_set, test_set = pickle.load(fin, encoding='latin1')\n",
    "    weights, biases = train(train_set)\n",
    "    acuratete(weights, biases, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
